{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good random segments, in Smith\n",
    "\n",
    "There is a lot of data in the Smith set. Less than half has oscillations, see `smith_analysis_oscillation_log.md`. To find segments of data with oscillations, I turn to FOOOF.\n",
    "\n",
    "FOOOF needs python3. So I put this path of project into an independent notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"4ae575b3-0849-4378-a8b7-b347c757b024\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"4ae575b3-0849-4378-a8b7-b347c757b024\");\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"4ae575b3-0849-4378-a8b7-b347c757b024\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '4ae575b3-0849-4378-a8b7-b347c757b024' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.7.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"4ae575b3-0849-4378-a8b7-b347c757b024\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"4ae575b3-0849-4378-a8b7-b347c757b024\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.io import export_png\n",
    "output_notebook()\n",
    "\n",
    "# -\n",
    "from fooof import FOOOF\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import resample\n",
    "from scipy.signal import welch, gaussian\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "# --\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "\n",
    "    return y\n",
    "\n",
    "# -\n",
    "def plot_grid_psd(x, m, fs, show_plot=False):\n",
    "    freqs, psd = create_psd(x[m], fs)\n",
    "    p = figure(plot_width=150, plot_height=150)\n",
    "    p.line(freqs, np.log10(psd), color=\"black\", alpha=1)\n",
    "    p.xaxis.axis_label = 'Freq (Hz)'\n",
    "    p.yaxis.axis_label = 'Log power (AU)'\n",
    "    p.x_range = Range1d(1, 50)\n",
    "    p.y_range = Range1d(-3, 5)\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.toolbar.logo = None\n",
    "    p.toolbar_location = None\n",
    "    \n",
    "    if show_plot:\n",
    "        show(p)\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "# -\n",
    "def random_fooof(X,\n",
    "                 num_windows,\n",
    "                 window_length,\n",
    "                 good_channels,\n",
    "                 fs=1000,\n",
    "                 alpha_range=(8, 16),\n",
    "                 fit_range=(3, 40),\n",
    "                 i_min=10000,\n",
    "                 max_iterations=25000,\n",
    "                 save_results=False):\n",
    "    \"\"\"FOOOF random channels and windows of X.\"\"\"\n",
    "    \n",
    "    # Init\n",
    "    fm = FOOOF(peak_width_limits=[2.0, 12.0])\n",
    "\n",
    "    # Est baseline std for all channels\n",
    "    std_ref = X.std()\n",
    "    mean_alpha = np.mean(alpha_range)\n",
    "\n",
    "    # -\n",
    "    m = 0  # Window count\n",
    "    k = 0  # Iter count\n",
    "    n_samples = X.shape[0] \n",
    "    \n",
    "    results = []\n",
    "    while m < num_windows:\n",
    "        # Update overall iter count\n",
    "        k += 1\n",
    "        if k > max_iterations:\n",
    "            break\n",
    "\n",
    "        # Sample random channel from the good\n",
    "        np.random.shuffle(good_channels)\n",
    "        c = good_channels[0]\n",
    "    \n",
    "        x = X[:, c]\n",
    "        \n",
    "\n",
    "        if i_min > n_samples:\n",
    "            raise ValueError(\"i_min must be less than {}\".format(i_max))\n",
    "            \n",
    "        # -\n",
    "        # Find a good window\n",
    "        stop_idx_search = True\n",
    "        while stop_idx_search:\n",
    "            # Update overall iter count\n",
    "            k += 1\n",
    "            if k > max_iterations:\n",
    "                break\n",
    "            \n",
    "            # Generate random i:j \n",
    "            i = np.random.randint(i_min, n_samples - window_length, 1)\n",
    "            j = i + window_length\n",
    "                  \n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            \n",
    "            # Basic QC pass?\n",
    "            if x[i:j].std() > (3 * std_ref):\n",
    "                continue\n",
    "\n",
    "            if j > n_samples:\n",
    "                raise ValueError(\n",
    "                    \"i ({}) exceeded n_samples {}\".format(i, n_samples))\n",
    "            \n",
    "            stop_idx_search = False\n",
    "            \n",
    "        # FOOOF x in the window\n",
    "        freqs, psd = create_psd(x[i:j], fs)\n",
    "        fm.fit(freqs, psd, fit_range)\n",
    "\n",
    "        # -\n",
    "        # Repack peak_params_ into seperate values\n",
    "        centers = []\n",
    "        powers = []\n",
    "        bws = []\n",
    "        for (center, amp, bw) in fm.peak_params_:\n",
    "            centers.append(center)\n",
    "            powers.append(amp)\n",
    "            bws.append(bw)\n",
    "        \n",
    "        centers = np.asarray(centers)\n",
    "        powers = np.asarray(powers)\n",
    "        bws = np.asarray(bws)\n",
    "        \n",
    "        # Found any peaks?\n",
    "        if centers.size == 0:\n",
    "            continue\n",
    "        \n",
    "        # -\n",
    "        # Find closest to mean alpha\n",
    "        idx = (np.abs(centers - mean_alpha)).argmin()\n",
    "        closest_peak = centers[idx]\n",
    "\n",
    "        # It is in range?\n",
    "        if (closest_peak >= alpha_range[0]) and (\n",
    "                closest_peak <= alpha_range[1]):\n",
    "\n",
    "            row = (m, c, i, j, closest_peak, powers[idx], bws[idx])\n",
    "            results.append(row)\n",
    "\n",
    "            m += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_fooof_results(name, results):\n",
    "    header = (\"m\", \"c\", \"i\", \"j\", \"center\", \"power\", \"bw\")\n",
    "\n",
    "    with open(name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for row in results:\n",
    "            writer.writerow(row)\n",
    "\n",
    "            \n",
    "def load_foof_results(name):\n",
    "    results = []\n",
    "    with open(name, 'r') as fi:\n",
    "        reader = csv.reader(fi, delimiter=\",\")\n",
    "        for i, row in enumerate(reader):\n",
    "            results.append(row)\n",
    "\n",
    "    header = results.pop()\n",
    "    \n",
    "    return header, results\n",
    "\n",
    "\n",
    "def create_psd(lfp, inrate, outrate=1000):\n",
    "    \"\"\"Calculate PSD from LFP/EEG data.\"\"\"\n",
    "    lfp = np.array(lfp)\n",
    "\n",
    "    if inrate != outrate:\n",
    "        lfp = resample(lfp, int(lfp.shape[0] * outrate / inrate))\n",
    "\n",
    "    # Calculate PSD\n",
    "    return welch(\n",
    "        lfp,\n",
    "        fs=outrate,\n",
    "        window='hanning',\n",
    "        nperseg=outrate,\n",
    "        noverlap=outrate / 2.0,\n",
    "        nfft=None,\n",
    "        detrend='linear',\n",
    "        return_onesided=True,\n",
    "        scaling='density')\n",
    "\n",
    "def create_times(t, dt):\n",
    "    n_steps = int(t * (1.0 / dt))\n",
    "    times = np.linspace(0, t, n_steps)\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/type/Data/Smith/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good files\n",
    "\n",
    "Found by manual plotting. See `smith_analysis_oscillation_log.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [\"Bo130408_s6ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Bo130408_s6ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Bo130409_s7ae_fixblank_active_0003_converted_ns2.mat\",\n",
    "\"Wi130116_s51ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Bo130404_s4ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Bo130405_s5ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Bo130405_s5ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Bo130405_s5ae_fixblank_active_0003_converted_ns2.mat\",\n",
    "\"Bo130418_s12ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Wi121219_s43ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Wi121219_s43ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Wi130129_s55ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Wi130129_s55ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Wi130205_s58ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Wi130205_s58ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Wi130207_s59ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Wi130207_s59ae_fixblank_active_0002_converted_ns2.mat\",\n",
    "\"Wi130207_s59ae_fixblank_active_0003_converted_ns2.mat\",\n",
    "\"Wi130208_s60ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Wi130211_s61ae_fixblank_active_0001_converted_ns2.mat\",\n",
    "\"Wi130212_s62ae_fixblank_active_0001_converted_ns2.mat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bo130408_s6ae_fixblank_active_0001_converted_ns2.mat\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"Running {}\".format(files[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#refs#',\n",
      " 'Fs',\n",
      " 'chanunit',\n",
      " 'data',\n",
      " 'label',\n",
      " 'nChans',\n",
      " 'nSamples',\n",
      " 'scale',\n",
      " 'timeStamps']\n"
     ]
    }
   ],
   "source": [
    "fi = h5py.File(os.path.join(DATA_PATH, files[i]))\n",
    "pprint(list(fi.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment time T 3486.306\n",
      "Times: [ 0.          0.001       0.002       0.003       0.004       0.005       0.006\n",
      "  0.007       0.008       0.009       0.01        0.011       0.012       0.013\n",
      "  0.014       0.015       0.016       0.017       0.01800001  0.01900001]\n"
     ]
    }
   ],
   "source": [
    "fs = float(fi['Fs'].value)\n",
    "n_samples = float(fi['nSamples'].value) \n",
    "T = n_samples / fs\n",
    "print(\"Experiment time T {}\".format(T))\n",
    "\n",
    "times = create_times(T, 1/fs)\n",
    "print(\"Times: {}\".format(times[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "and print stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (3486306, 104)\n"
     ]
    }
   ],
   "source": [
    "X = fi['data'].value\n",
    "print(\"Data shape: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example random FOOOF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/type/anaconda/envs/py3/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "results = random_fooof(X, 10, 10*fs, list(range(0, 95)), fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  82,\n",
      "  996564,\n",
      "  1006564,\n",
      "  13.120495413143001,\n",
      "  0.4266003319647278,\n",
      "  3.8430732080439958),\n",
      " (1,\n",
      "  62,\n",
      "  1189038,\n",
      "  1199038,\n",
      "  9.3634144391113221,\n",
      "  0.27757741888425569,\n",
      "  3.5632169095804933),\n",
      " (2,\n",
      "  54,\n",
      "  2120091,\n",
      "  2130091,\n",
      "  10.907014260519945,\n",
      "  0.36302118818209239,\n",
      "  6.0054855545238377)]\n"
     ]
    }
   ],
   "source": [
    "pprint(results[:3])\n",
    "save_fooof_results(\"test.csv\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Results seem sane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOOOF all the good files\n",
    "\n",
    "- 6000 samples / file (or 600 per electrode on average)\n",
    "\n",
    "### LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [2:00:42<00:00, 344.90s/it]\n"
     ]
    }
   ],
   "source": [
    "sample_percent = 0.1\n",
    "channels = list(range(0, 95))\n",
    "\n",
    "for fi in tqdm(files):\n",
    "    # Load the handle\n",
    "    hdf = h5py.File(os.path.join(DATA_PATH, fi))\n",
    "    \n",
    "    # Extract time information\n",
    "    fs = float(hdf['Fs'].value)\n",
    "    n_samples = float(hdf['nSamples'].value) \n",
    "    T = n_samples / fs\n",
    "    \n",
    "    # Number of samples to pull, as a percent of T\n",
    "    n_window = int(n_samples * sample_percent)\n",
    "    \n",
    "    # Window length (in samples)\n",
    "    l = 10*fs\n",
    "    \n",
    "    # Get the data\n",
    "    X = hdf['data'].value\n",
    "\n",
    "    # Extract name, drop extension\n",
    "    fi_name = os.path.splitext(fi)[0]\n",
    "    \n",
    "    # Do random FOOOF\n",
    "    results = random_fooof(X, n_window, l, channels, fs=fs)\n",
    "    \n",
    "    # Save the result\n",
    "    save_fooof_results(\n",
    "        \"{}_segments.csv\".format(os.path.join(DATA_PATH, fi_name)), \n",
    "        results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine random random segments.\n",
    "\n",
    "Find all the segment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all the segments files (created above)\n",
    "pattern = \"*_segments.csv\"\n",
    "results_files = glob(os.path.join(DATA_PATH, pattern))\n",
    "pprint([(i, fi) for i, fi in enumerate(results_files)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "result_file = results_files[i]\n",
    "print(\">>> Analyzing segments from {}\".format(os.path.split(result_file)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load results\n",
    "header, results = load_foof_results(os.path.join(DATA_PATH, result_file))\n",
    "\n",
    "# Load raw data\n",
    "data_file = (result_file.split('_')[:-1])\n",
    "data_file = \"_\".join(data_file)\n",
    "data_file += \".mat\"\n",
    "print(\">>> Loading {}\".format(data_file))\n",
    "\n",
    "fi = h5py.File(data_file)\n",
    "X = fi['data'].value\n",
    "print(\"Data shape {}\".format(X.shape))\n",
    "\n",
    "fs = float(fi['Fs'].value)\n",
    "n_samples = float(fi['nSamples'].value) \n",
    "T = n_samples / fs\n",
    "print(\"Experiment time T {}\".format(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a segment\n",
    "\n",
    "...A row from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m, c, i, j, peak, power, bw = results[n]\n",
    "m = int(m)\n",
    "c = int(c)\n",
    "i = int(i)\n",
    "j = int(j)\n",
    "peak = float(peak)\n",
    "power = float(power)\n",
    "bw = float(bw)\n",
    "\n",
    "times = create_times(10, 1/fs)\n",
    "print(times.shape)\n",
    "print(m, c, i, j, peak, power, bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = X[i:j, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\">>> x shape {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -\n",
    "x_alpha = butter_bandpass_filter(x, peak - bw, peak + bw, fs, order=2)\n",
    "x_hil = np.abs(hilbert(x_alpha))\n",
    "x_filt = butter_bandpass_filter(x, 3, 100, fs, order=2)\n",
    "\n",
    "p = figure(plot_width=800, plot_height=300)\n",
    "p.line(times, x_filt, color=\"black\", alpha=0.6)\n",
    "p.line(times, x_alpha, color=\"red\", alpha=0.6)\n",
    "p.line(times, x_hil, color=\"red\", line_width=3, alpha=.3)\n",
    "p.xaxis.axis_label = 'Time (s)'\n",
    "p.yaxis.axis_label = 'LFP (uV)'\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None\n",
    "show(p)\n",
    "\n",
    "# -\n",
    "freqs, psd = create_psd(x, fs, fs)\n",
    "peak_line = np.linspace(psd.min(), psd.max(), 10)\n",
    "\n",
    "p = figure(plot_width=300, plot_height=300, x_axis_type=\"log\", y_axis_type=\"log\")\n",
    "p.line(freqs, psd, color=\"black\", alpha=1)\n",
    "p.line(x=np.repeat(peak, peak_line.size), y=peak_line)\n",
    "p.xaxis.axis_label = 'Freq (Hz)'\n",
    "p.yaxis.axis_label = 'Log power (AU)'\n",
    "p.x_range = Range1d(1, 50)\n",
    "# p.y_range = Range1d(-3, 5)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
